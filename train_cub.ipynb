{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import sys\r\n",
    "import timm\r\n",
    "import time\r\n",
    "import torch\r\n",
    "import numpy as np\r\n",
    "import torch.nn as nn\r\n",
    "import torch.optim as optim\r\n",
    "import utils.DataSet_Aug as DataSet\r\n",
    "from utils.LabelSmooth import LabelSmoothCELoss\r\n",
    "\r\n",
    "\r\n",
    "###### Function: Train the samples after augmentation ######\r\n",
    "\r\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "SAVE_PATH = './vit_cub.pth'\r\n",
    "EPOCHS = 50\r\n",
    "BATCH_SIZE = 4\r\n",
    "LEARING_RATE_CLASSIFIER = 0.001\r\n",
    "LEARING_RATE_FEATURES = 0.0002\r\n",
    "MOMENTUM = 0.8\r\n",
    "WEIGHT_DECAY = 5e-4\r\n",
    "STEP_SIZE = 30\r\n",
    "STEP_GAMMA = 0.3\r\n",
    "SMOOTHING =0.4"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "train_loader = torch.utils.data.DataLoader(\r\n",
    "    DataSet.load_datasets(dataset='CUB_200_2011', root='data/CUB_200_2011',\r\n",
    "                           train=True, transform=DataSet.data_transform['train']),\r\n",
    "    batch_size=BATCH_SIZE, shuffle=True,\r\n",
    "    num_workers=2)  # load the trainset\r\n",
    "\r\n",
    "test_loader = torch.utils.data.DataLoader(\r\n",
    "    DataSet.load_datasets(dataset='CUB_200_2011', root='data/CUB_200_2011',\r\n",
    "                          train=False, transform=DataSet.data_transform['test']),\r\n",
    "    batch_size=BATCH_SIZE, shuffle=False,\r\n",
    "    num_workers=2)  # load the testset\r\n",
    "\r\n",
    "\r\n",
    "net = timm.create_model('vit_base_patch16_384',\r\n",
    "                        pretrained=True)  # define the model\r\n",
    "inchannel = net.head.in_features\r\n",
    "net.head = nn.Linear(inchannel, 200)\r\n",
    "net.to(device)\r\n",
    "\r\n",
    "labelSmoothCELoss = LabelSmoothCELoss()\r\n",
    "\r\n",
    "# using differential learning rate strategy\r\n",
    "high_rate_params = []\r\n",
    "low_rate_params = []\r\n",
    "for name, params in net.named_parameters():\r\n",
    "    if 'head' in name:\r\n",
    "        high_rate_params += [params]\r\n",
    "    else:\r\n",
    "        low_rate_params += [params]\r\n",
    "\r\n",
    "# define the optimizer\r\n",
    "optimizer = optim.SGD(\r\n",
    "    params=[\r\n",
    "        {\"params\": high_rate_params, 'lr': LEARING_RATE_CLASSIFIER},\r\n",
    "        {\"params\": low_rate_params},\r\n",
    "    ],\r\n",
    "    lr=LEARING_RATE_FEATURES, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY\r\n",
    ")\r\n",
    "\r\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE,\r\n",
    "                                      gamma=STEP_GAMMA, last_epoch=-1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "print(EPOCHS)\r\n",
    "best_accuracy = 0.0\r\n",
    "\r\n",
    "for epoch in range(EPOCHS):\r\n",
    "\r\n",
    "    print(device)\r\n",
    "    epoch_start = time.time()\r\n",
    "    print('Epoch:{}'.format(epoch + 1))\r\n",
    "\r\n",
    "    # train\r\n",
    "    net.train()\r\n",
    "    train_loss_list = []  # record the loss of every batch\r\n",
    "    train_accuracy_list = []  # record the accuracy of every batch\r\n",
    "\r\n",
    "    for step, data in enumerate(train_loader, start=0):\r\n",
    "\r\n",
    "        images, labels = data\r\n",
    "        images, labels = images.to(device), labels.to(device)\r\n",
    "        logits = net(images)\r\n",
    "        loss = labelSmoothCELoss(logits, labels)\r\n",
    "\r\n",
    "        optimizer.zero_grad()\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "\r\n",
    "        train_loss = loss.item()\r\n",
    "        train_loss_list.append(train_loss)\r\n",
    "\r\n",
    "        prediction = torch.max(logits, dim=1)[-1]\r\n",
    "        train_accuracy = prediction.eq(labels).cpu().float().mean()\r\n",
    "        train_accuracy_list.append(train_accuracy)\r\n",
    "\r\n",
    "        rate = (step + 1) / len(train_loader)\r\n",
    "        a = \"*\" * int(rate * 50)\r\n",
    "        b = \".\" * int((1 - rate) * 50)\r\n",
    "        print(\"\\rtrain loss: {:^3.0f}%[{}->{}]{:.3f}\".format(\r\n",
    "            int(rate * 100), a, b, loss), end=\"\")  # draw the progress bar\r\n",
    "    print()\r\n",
    "    print('train_loss:{:.3f},train_accuracy:{:.3f}'.format(\r\n",
    "        np.mean(train_loss_list), np.mean(train_accuracy_list)))\r\n",
    "\r\n",
    "    # test\r\n",
    "    net.eval()\r\n",
    "    test_loss_list = []\r\n",
    "    test_accuracy_list = []\r\n",
    "\r\n",
    "    with torch.no_grad():\r\n",
    "        for step, data in enumerate(test_loader, start=0):\r\n",
    "\r\n",
    "            images, labels = data\r\n",
    "            images, labels = images.to(device), labels.to(device)\r\n",
    "            logits = net(images)\r\n",
    "            loss = labelSmoothCELoss(logits, labels)\r\n",
    "\r\n",
    "            test_loss = loss.item()\r\n",
    "            test_loss_list.append(test_loss)\r\n",
    "\r\n",
    "            prediction = torch.max(logits, dim=1)[-1]\r\n",
    "            test_accuracy = prediction.eq(labels).cpu().float().mean()\r\n",
    "            test_accuracy_list.append(test_accuracy)\r\n",
    "\r\n",
    "            rate = (step + 1) / len(test_loader)\r\n",
    "            a = \"*\" * int(rate * 50)\r\n",
    "            b = \".\" * int((1 - rate) * 50)\r\n",
    "            print(\"\\rtest loss: {:^3.0f}%[{}->{}]{:.3f}\".format(\r\n",
    "                int(rate * 100), a, b, loss), end=\"\")\r\n",
    "        print()\r\n",
    "\r\n",
    "        test_accuracy = np.mean(test_accuracy_list)\r\n",
    "        if test_accuracy > best_accuracy:\r\n",
    "            best_accuracy = test_accuracy\r\n",
    "            torch.save(net.state_dict(), SAVE_PATH)\r\n",
    "\r\n",
    "        epoch_end = time.time()\r\n",
    "        print('test_loss:{:.3f},test_accuracy:{:.3f},epoch_time:{:.3f}'.format(\r\n",
    "            np.mean(test_loss_list), np.mean(test_accuracy_list), (epoch_end-epoch_start)))\r\n",
    "    scheduler.step()\r\n",
    "\r\n",
    "print('Finished Training')\r\n",
    "print('The best accuracy : %.3f' % best_accuracy)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "50\n",
      "cuda:0\n",
      "Epoch:1\n",
      "train loss: 100%[**************************************************->]2.999\n",
      "train_loss:3.997,train_accuracy:0.533\n",
      "test loss: 100%[**************************************************->]3.002\n",
      "test_loss:3.326,test_accuracy:0.791,epoch_time:204.812\n",
      "cuda:0\n",
      "Epoch:2\n",
      "train loss: 100%[**************************************************->]3.441\n",
      "train_loss:3.386,train_accuracy:0.772\n",
      "test loss: 100%[**************************************************->]3.045\n",
      "test_loss:3.200,test_accuracy:0.858,epoch_time:204.356\n",
      "cuda:0\n",
      "Epoch:3\n",
      "train loss: 100%[**************************************************->]3.252\n",
      "train_loss:3.291,train_accuracy:0.819\n",
      "test loss: 100%[**************************************************->]2.916\n",
      "test_loss:3.155,test_accuracy:0.879,epoch_time:204.331\n",
      "cuda:0\n",
      "Epoch:4\n",
      "train loss: 100%[**************************************************->]3.234\n",
      "train_loss:3.240,train_accuracy:0.846\n",
      "test loss: 100%[**************************************************->]2.936\n",
      "test_loss:3.127,test_accuracy:0.890,epoch_time:204.445\n",
      "cuda:0\n",
      "Epoch:5\n",
      "train loss: 100%[**************************************************->]3.391\n",
      "train_loss:3.195,train_accuracy:0.864\n",
      "test loss: 100%[**************************************************->]2.877\n",
      "test_loss:3.112,test_accuracy:0.894,epoch_time:204.518\n",
      "cuda:0\n",
      "Epoch:6\n",
      "train loss: 100%[**************************************************->]3.023\n",
      "train_loss:3.176,train_accuracy:0.866\n",
      "test loss: 100%[**************************************************->]2.932\n",
      "test_loss:3.101,test_accuracy:0.899,epoch_time:204.430\n",
      "cuda:0\n",
      "Epoch:7\n",
      "train loss: 100%[**************************************************->]3.046\n",
      "train_loss:3.154,train_accuracy:0.882\n",
      "test loss: 100%[**************************************************->]2.874\n",
      "test_loss:3.090,test_accuracy:0.905,epoch_time:204.462\n",
      "cuda:0\n",
      "Epoch:8\n",
      "train loss: 100%[**************************************************->]2.884\n",
      "train_loss:3.134,train_accuracy:0.891\n",
      "test loss: 100%[**************************************************->]2.870\n",
      "test_loss:3.092,test_accuracy:0.903,epoch_time:203.687\n",
      "cuda:0\n",
      "Epoch:9\n",
      "train loss: 100%[**************************************************->]3.007\n",
      "train_loss:3.108,train_accuracy:0.899\n",
      "test loss: 100%[**************************************************->]2.863\n",
      "test_loss:3.079,test_accuracy:0.905,epoch_time:203.483\n",
      "cuda:0\n",
      "Epoch:10\n",
      "train loss: 100%[**************************************************->]3.009\n",
      "train_loss:3.101,train_accuracy:0.900\n",
      "test loss: 100%[**************************************************->]2.859\n",
      "test_loss:3.075,test_accuracy:0.906,epoch_time:204.448\n",
      "cuda:0\n",
      "Epoch:11\n",
      "train loss: 100%[**************************************************->]2.985\n",
      "train_loss:3.091,train_accuracy:0.909\n",
      "test loss: 100%[**************************************************->]2.866\n",
      "test_loss:3.072,test_accuracy:0.908,epoch_time:204.097\n",
      "cuda:0\n",
      "Epoch:12\n",
      "train loss: 100%[**************************************************->]2.927\n",
      "train_loss:3.076,train_accuracy:0.913\n",
      "test loss: 100%[**************************************************->]2.883\n",
      "test_loss:3.079,test_accuracy:0.902,epoch_time:203.528\n",
      "cuda:0\n",
      "Epoch:13\n",
      "train loss: 100%[**************************************************->]2.936\n",
      "train_loss:3.077,train_accuracy:0.916\n",
      "test loss: 100%[**************************************************->]2.864\n",
      "test_loss:3.068,test_accuracy:0.908,epoch_time:203.586\n",
      "cuda:0\n",
      "Epoch:14\n",
      "train loss: 100%[**************************************************->]2.944\n",
      "train_loss:3.058,train_accuracy:0.922\n",
      "test loss: 100%[**************************************************->]2.867\n",
      "test_loss:3.063,test_accuracy:0.911,epoch_time:204.177\n",
      "cuda:0\n",
      "Epoch:15\n",
      "train loss: 100%[**************************************************->]2.927\n",
      "train_loss:3.055,train_accuracy:0.923\n",
      "test loss: 100%[**************************************************->]2.848\n",
      "test_loss:3.074,test_accuracy:0.907,epoch_time:203.412\n",
      "cuda:0\n",
      "Epoch:16\n",
      "train loss: 100%[**************************************************->]2.838\n",
      "train_loss:3.053,train_accuracy:0.922\n",
      "test loss: 100%[**************************************************->]2.865\n",
      "test_loss:3.065,test_accuracy:0.908,epoch_time:203.438\n",
      "cuda:0\n",
      "Epoch:17\n",
      "train loss: 100%[**************************************************->]2.897\n",
      "train_loss:3.036,train_accuracy:0.930\n",
      "test loss: 100%[**************************************************->]2.842\n",
      "test_loss:3.062,test_accuracy:0.911,epoch_time:203.595\n",
      "cuda:0\n",
      "Epoch:18\n",
      "train loss: 100%[**************************************************->]2.920\n",
      "train_loss:3.030,train_accuracy:0.934\n",
      "test loss: 100%[**************************************************->]2.845\n",
      "test_loss:3.057,test_accuracy:0.911,epoch_time:203.536\n",
      "cuda:0\n",
      "Epoch:19\n",
      "train loss: 100%[**************************************************->]3.647\n",
      "train_loss:3.032,train_accuracy:0.930\n",
      "test loss: 100%[**************************************************->]2.850\n",
      "test_loss:3.056,test_accuracy:0.913,epoch_time:204.377\n",
      "cuda:0\n",
      "Epoch:20\n",
      "train loss: 100%[**************************************************->]3.064\n",
      "train_loss:3.019,train_accuracy:0.937\n",
      "test loss: 100%[**************************************************->]2.848\n",
      "test_loss:3.055,test_accuracy:0.909,epoch_time:203.527\n",
      "cuda:0\n",
      "Epoch:21\n",
      "train loss: 100%[**************************************************->]2.991\n",
      "train_loss:3.023,train_accuracy:0.935\n",
      "test loss: 100%[**************************************************->]2.864\n",
      "test_loss:3.055,test_accuracy:0.913,epoch_time:203.385\n",
      "cuda:0\n",
      "Epoch:22\n",
      "train loss: 100%[**************************************************->]2.845\n",
      "train_loss:3.010,train_accuracy:0.939\n",
      "test loss: 100%[**************************************************->]2.852\n",
      "test_loss:3.068,test_accuracy:0.912,epoch_time:203.252\n",
      "cuda:0\n",
      "Epoch:23\n",
      "train loss: 100%[**************************************************->]2.821\n",
      "train_loss:2.999,train_accuracy:0.945\n",
      "test loss: 100%[**************************************************->]2.852\n",
      "test_loss:3.053,test_accuracy:0.912,epoch_time:203.549\n",
      "cuda:0\n",
      "Epoch:24\n",
      "train loss: 100%[**************************************************->]3.053\n",
      "train_loss:3.009,train_accuracy:0.940\n",
      "test loss: 100%[**************************************************->]2.850\n",
      "test_loss:3.062,test_accuracy:0.914,epoch_time:204.412\n",
      "cuda:0\n",
      "Epoch:25\n",
      "train loss: 100%[**************************************************->]2.870\n",
      "train_loss:2.996,train_accuracy:0.944\n",
      "test loss: 100%[**************************************************->]2.853\n",
      "test_loss:3.056,test_accuracy:0.909,epoch_time:203.485\n",
      "cuda:0\n",
      "Epoch:26\n",
      "train loss: 100%[**************************************************->]2.860\n",
      "train_loss:2.989,train_accuracy:0.949\n",
      "test loss: 100%[**************************************************->]2.859\n",
      "test_loss:3.059,test_accuracy:0.911,epoch_time:203.401\n",
      "cuda:0\n",
      "Epoch:27\n",
      "train loss: 100%[**************************************************->]2.854\n",
      "train_loss:2.989,train_accuracy:0.947\n",
      "test loss: 100%[**************************************************->]2.857\n",
      "test_loss:3.063,test_accuracy:0.913,epoch_time:203.308\n",
      "cuda:0\n",
      "Epoch:28\n",
      "train loss: 100%[**************************************************->]3.032\n",
      "train_loss:2.990,train_accuracy:0.948\n",
      "test loss: 100%[**************************************************->]2.860\n",
      "test_loss:3.055,test_accuracy:0.911,epoch_time:203.248\n",
      "cuda:0\n",
      "Epoch:29\n",
      "train loss: 100%[**************************************************->]3.078\n",
      "train_loss:2.981,train_accuracy:0.949\n",
      "test loss: 100%[**************************************************->]2.854\n",
      "test_loss:3.058,test_accuracy:0.912,epoch_time:203.340\n",
      "cuda:0\n",
      "Epoch:30\n",
      "train loss: 100%[**************************************************->]2.928\n",
      "train_loss:2.976,train_accuracy:0.951\n",
      "test loss: 100%[**************************************************->]2.857\n",
      "test_loss:3.057,test_accuracy:0.911,epoch_time:203.480\n",
      "cuda:0\n",
      "Epoch:31\n",
      "train loss: 100%[**************************************************->]3.418\n",
      "train_loss:2.967,train_accuracy:0.951\n",
      "test loss: 100%[**************************************************->]2.843\n",
      "test_loss:3.050,test_accuracy:0.916,epoch_time:204.384\n",
      "cuda:0\n",
      "Epoch:32\n",
      "train loss: 100%[**************************************************->]3.173\n",
      "train_loss:2.965,train_accuracy:0.955\n",
      "test loss: 100%[**************************************************->]2.845\n",
      "test_loss:3.046,test_accuracy:0.918,epoch_time:204.357\n",
      "cuda:0\n",
      "Epoch:33\n",
      "train loss: 100%[**************************************************->]2.866\n",
      "train_loss:2.956,train_accuracy:0.959\n",
      "test loss: 100%[**************************************************->]2.841\n",
      "test_loss:3.047,test_accuracy:0.917,epoch_time:203.412\n",
      "cuda:0\n",
      "Epoch:34\n",
      "train loss: 100%[**************************************************->]2.860\n",
      "train_loss:2.962,train_accuracy:0.956\n",
      "test loss: 100%[**************************************************->]2.846\n",
      "test_loss:3.049,test_accuracy:0.915,epoch_time:203.554\n",
      "cuda:0\n",
      "Epoch:35\n",
      "train loss: 100%[**************************************************->]2.865\n",
      "train_loss:2.957,train_accuracy:0.957\n",
      "test loss: 100%[**************************************************->]2.843\n",
      "test_loss:3.049,test_accuracy:0.915,epoch_time:203.471\n",
      "cuda:0\n",
      "Epoch:36\n",
      "train loss: 100%[**************************************************->]2.821\n",
      "train_loss:2.950,train_accuracy:0.960\n",
      "test loss: 100%[**************************************************->]2.835\n",
      "test_loss:3.049,test_accuracy:0.915,epoch_time:203.453\n",
      "cuda:0\n",
      "Epoch:37\n",
      "train loss: 100%[**************************************************->]2.848\n",
      "train_loss:2.959,train_accuracy:0.955\n",
      "test loss: 100%[**************************************************->]2.838\n",
      "test_loss:3.047,test_accuracy:0.914,epoch_time:203.407\n",
      "cuda:0\n",
      "Epoch:38\n",
      "train loss: 100%[**************************************************->]2.841\n",
      "train_loss:2.949,train_accuracy:0.958\n",
      "test loss: 100%[**************************************************->]2.846\n",
      "test_loss:3.046,test_accuracy:0.915,epoch_time:203.386\n",
      "cuda:0\n",
      "Epoch:39\n",
      "train loss: 100%[**************************************************->]3.991\n",
      "train_loss:2.960,train_accuracy:0.956\n",
      "test loss: 100%[**************************************************->]2.841\n",
      "test_loss:3.049,test_accuracy:0.917,epoch_time:203.456\n",
      "cuda:0\n",
      "Epoch:40\n",
      "train loss: 100%[**************************************************->]2.886\n",
      "train_loss:2.949,train_accuracy:0.958\n",
      "test loss: 100%[**************************************************->]2.839\n",
      "test_loss:3.045,test_accuracy:0.914,epoch_time:203.603\n",
      "cuda:0\n",
      "Epoch:41\n",
      "train loss: 100%[**************************************************->]2.842\n",
      "train_loss:2.951,train_accuracy:0.958\n",
      "test loss: 100%[**************************************************->]2.837\n",
      "test_loss:3.051,test_accuracy:0.915,epoch_time:203.869\n",
      "cuda:0\n",
      "Epoch:42\n",
      "train loss: 100%[**************************************************->]2.870\n",
      "train_loss:2.959,train_accuracy:0.954\n",
      "test loss: 100%[**************************************************->]2.838\n",
      "test_loss:3.048,test_accuracy:0.914,epoch_time:203.705\n",
      "cuda:0\n",
      "Epoch:43\n",
      "train loss: 100%[**************************************************->]3.268\n",
      "train_loss:2.954,train_accuracy:0.956\n",
      "test loss: 100%[**************************************************->]2.839\n",
      "test_loss:3.051,test_accuracy:0.915,epoch_time:203.602\n",
      "cuda:0\n",
      "Epoch:44\n",
      "train loss: 100%[**************************************************->]2.834\n",
      "train_loss:2.947,train_accuracy:0.961\n",
      "test loss: 100%[**************************************************->]2.837\n",
      "test_loss:3.052,test_accuracy:0.915,epoch_time:203.321\n",
      "cuda:0\n",
      "Epoch:45\n",
      "train loss: 100%[**************************************************->]2.851\n",
      "train_loss:2.942,train_accuracy:0.961\n",
      "test loss: 100%[**************************************************->]2.843\n",
      "test_loss:3.048,test_accuracy:0.916,epoch_time:203.616\n",
      "cuda:0\n",
      "Epoch:46\n",
      "train loss: 100%[**************************************************->]3.827\n",
      "train_loss:2.949,train_accuracy:0.956\n",
      "test loss: 100%[**************************************************->]2.842\n",
      "test_loss:3.048,test_accuracy:0.913,epoch_time:203.516\n",
      "cuda:0\n",
      "Epoch:47\n",
      "train loss: 100%[**************************************************->]2.833\n",
      "train_loss:2.941,train_accuracy:0.961\n",
      "test loss: 100%[**************************************************->]2.841\n",
      "test_loss:3.050,test_accuracy:0.914,epoch_time:203.627\n",
      "cuda:0\n",
      "Epoch:48\n",
      "train loss: 100%[**************************************************->]3.006\n",
      "train_loss:2.949,train_accuracy:0.958\n",
      "test loss: 100%[**************************************************->]2.837\n",
      "test_loss:3.050,test_accuracy:0.913,epoch_time:203.628\n",
      "cuda:0\n",
      "Epoch:49\n",
      "train loss: 100%[**************************************************->]4.213\n",
      "train_loss:2.942,train_accuracy:0.960\n",
      "test loss: 100%[**************************************************->]2.837\n",
      "test_loss:3.054,test_accuracy:0.915,epoch_time:203.536\n",
      "cuda:0\n",
      "Epoch:50\n",
      "train loss: 100%[**************************************************->]2.831\n",
      "train_loss:2.938,train_accuracy:0.963\n",
      "test loss: 100%[**************************************************->]2.838\n",
      "test_loss:3.052,test_accuracy:0.914,epoch_time:202.300\n",
      "Finished Training\n",
      "The best accuracy : 0.918\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}